{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 20:42:12.158999: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 20:42:12.771101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # add parent directory to the system path\n",
    "from utils_data import *\n",
    "from utils_model import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84479 images belonging to 524 classes.\n",
      "Found 2620 images belonging to 524 classes.\n",
      "Found 2620 images belonging to 524 classes.\n"
     ]
    }
   ],
   "source": [
    "# get the data ready\n",
    "root_name = \"Research\"\n",
    "train_path, test_path, val_path = make_data_path(root_name=root_name)\n",
    "\n",
    "DataGenerator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_data, test_data, val_data = make_data_ready(\n",
    "    DataGenerator, train_path, test_path, val_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 20:42:20.458394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:20.475691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:20.476100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:20.477303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:20.477651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:20.477957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:21.329784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:21.330255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:21.330274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-30 20:42:21.330591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 20:42:21.330639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3888 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# ________________ CONFIG THE BASE MODELS ________________ #\n",
    "weights = \"imagenet\"\n",
    "input_shape = (224, 224, 3)\n",
    "num_class = 524\n",
    "\n",
    "include_top = False\n",
    "base_trainable = False\n",
    "pooling = \"max\"\n",
    "learning_rate = 0.1\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "model_funcs = [\n",
    "    tf.keras.applications.inception_v3.InceptionV3,\n",
    "    tf.keras.applications.resnet50.ResNet50,\n",
    "    tf.keras.applications.mobilenet.MobileNet,\n",
    "    tf.keras.applications.mobilenet_v2.MobileNetV2,\n",
    "    tf.keras.applications.efficientnet.EfficientNetB0,\n",
    "    tf.keras.applications.efficientnet_v2.EfficientNetV2B0,\n",
    "]\n",
    "\n",
    "model_0s = {}\n",
    "\n",
    "for model_func in model_funcs:\n",
    "    model_name = model_func.__name__\n",
    "\n",
    "    model_0s[model_name] = configure_model_base(\n",
    "        model_func=model_func,\n",
    "        weights=weights,\n",
    "        include_top=False,\n",
    "        base_trainable=False,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        num_class=num_class,\n",
    "        learning_rate=learning_rate,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 20:42:39.328389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-30 20:42:41.590938: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-30 20:42:43.673649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x319edcc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-30 20:42:43.673697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-09-30 20:42:43.746374: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2640 [..............................] - ETA: 7:38:01 - loss: 9.9543 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 20:42:44.076952: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-30 20:42:44.158966: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 170s 61ms/step - loss: 447.6525 - accuracy: 0.3993 - val_loss: 297.6126 - val_accuracy: 0.5875\n",
      "82/82 [==============================] - 7s 83ms/step - loss: 241.4987 - accuracy: 0.6053\n",
      "2640/2640 [==============================] - 241s 90ms/step - loss: 601.8671 - accuracy: 0.0156 - val_loss: 394.3858 - val_accuracy: 0.0156\n",
      "82/82 [==============================] - 8s 98ms/step - loss: 392.4375 - accuracy: 0.0324\n",
      "2640/2640 [==============================] - 260s 98ms/step - loss: 768.8514 - accuracy: 0.2919 - val_loss: 310.5617 - val_accuracy: 0.5266\n",
      "82/82 [==============================] - 68s 824ms/step - loss: 293.2017 - accuracy: 0.5305\n",
      "2640/2640 [==============================] - 1022s 384ms/step - loss: 358.3225 - accuracy: 0.4534 - val_loss: 278.2589 - val_accuracy: 0.6156\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 212.5779 - accuracy: 0.6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:12:33.476666: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 660s 248ms/step - loss: 2331.2712 - accuracy: 0.0018 - val_loss: 1983.5496 - val_accuracy: 0.0016\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1989.2185 - accuracy: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 21:23:48.979878: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/efficientnetv2-b0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 297s 110ms/step - loss: 307.5295 - accuracy: 0.0018 - val_loss: 265.9044 - val_accuracy: 0.0000e+00\n",
      "82/82 [==============================] - 10s 123ms/step - loss: 261.0547 - accuracy: 0.0019\n"
     ]
    }
   ],
   "source": [
    "# ________________ TEST TRAIN THE BASE MODELS ________________ #\n",
    "history = {}\n",
    "metrics = {}\n",
    "\n",
    "for model_name, model_0 in model_0s.items():\n",
    "    # train the models\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    history[model_name] = model_0.fit(\n",
    "        train_data,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(train_data),\n",
    "        validation_data=val_data,\n",
    "        validation_steps=int(0.25 * len(val_data)),\n",
    "    )\n",
    "\n",
    "    end_time = time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # save metrics for the models\n",
    "    metrics[model_name] = {\n",
    "        \"train_loss\": history[model_name].history[\"loss\"],\n",
    "        \"train_accuracy\": history[model_name].history[\"accuracy\"],\n",
    "        \"val_loss\": history[model_name].history[\"val_loss\"],\n",
    "        \"val_accuracy\": history[model_name].history[\"val_accuracy\"],\n",
    "        \"execution_time\": execution_time,\n",
    "    }\n",
    "\n",
    "    # evaluate the model on test data and save the results\n",
    "    test_loss, test_accuracy = model_0.evaluate(test_data)\n",
    "    metrics[model_name][\"test_loss\"] = test_loss\n",
    "    metrics[model_name][\"test_accuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../output/data\"\n",
    "file_name = \"model_performance_log.json\"\n",
    "save_metric(metrics, file_name, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomException",
     "evalue": "Error occured in the script, name: [/home/hoangng/Projects/Bird_classification/Research/notebook/../utils_model.py], line number: [126] error message: [[Errno 2] No such file or directory: '../output/data/model_performance_mobilenet_finetune2.json']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Bird_classification/Research/notebook/../utils_model.py:126\u001b[0m, in \u001b[0;36mload_dict_from_json\u001b[0;34m(file_name, file_path)\u001b[0m\n\u001b[1;32m    124\u001b[0m full_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(file_path, file_name)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(full_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    127\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/data/model_performance_mobilenet_finetune2.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../output/data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_performance_mobilenet_finetune2.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m loaded_metrics \u001b[39m=\u001b[39m load_dict_from_json(file_name, file_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m nrows \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hoangng/Projects/Bird_classification/Research/notebook/test_model_base.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m ncols \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Bird_classification/Research/notebook/../utils_model.py:131\u001b[0m, in \u001b[0;36mload_dict_from_json\u001b[0;34m(file_name, file_path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m    130\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[0;31mCustomException\u001b[0m: Error occured in the script, name: [/home/hoangng/Projects/Bird_classification/Research/notebook/../utils_model.py], line number: [126] error message: [[Errno 2] No such file or directory: '../output/data/model_performance_mobilenet_finetune2.json']"
     ]
    }
   ],
   "source": [
    "file_path = \"../output/data\"\n",
    "file_name = \"model_performance_mobilenet_finetune2.json\"\n",
    "\n",
    "loaded_metrics = load_dict_from_json(file_name, file_path)\n",
    "\n",
    "nrows = 6\n",
    "ncols = 2\n",
    "width = 10\n",
    "height = nrows * width/ncols\n",
    "\n",
    "figure = visualize_metric(loaded_metrics, nrows=nrows, ncols=ncols, figsize=(width, height))\n",
    "# save_plot(figure, file_name, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
